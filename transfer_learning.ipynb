{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79183a3-f588-4bb3-ba89-64d0874236df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ic-lab/miniconda3/envs/torch_v1.9_gpu/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24740cb3-9c85-4b16-95e2-076d846baf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_datasets = []\n",
    "\n",
    "# Task 1\n",
    "task1_data = np.load('./cwru1_X_train.npy')\n",
    "task1_labels = np.load('./cwru2_y_train.npy')\n",
    "\n",
    "# Task 2\n",
    "task2_data = np.load('./cwru2_X_train.npy')\n",
    "task2_labels = np.load('./cwru2_y_train.npy')\n",
    "\n",
    "# Task 3\n",
    "task3_data = np.load('./cwru3_X_train.npy')\n",
    "task3_labels = np.load('./cwru3_y_train.npy')\n",
    "\n",
    "# Task 4\n",
    "task4_data = np.load('./cwru4_X_train.npy')\n",
    "task4_labels = np.load('./cwru4_y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3dbef2-fcca-4504-8c57-847e1d5d61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "# Task 1\n",
    "task1_data = torch.from_numpy(task1_data)\n",
    "task1_labels = torch.from_numpy(task1_labels)\n",
    "\n",
    "# Task 2\n",
    "task2_data = torch.from_numpy(task2_data)\n",
    "task2_labels = torch.from_numpy(task2_labels)\n",
    "\n",
    "# Task 3\n",
    "task3_data = torch.from_numpy(task3_data)\n",
    "task3_labels = torch.from_numpy(task3_labels)\n",
    "\n",
    "# Task 4\n",
    "task4_data = torch.from_numpy(task4_data).double()\n",
    "task4_labels = torch.from_numpy(task4_labels).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df81a05e-9aa6-49b4-a463-63632474e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transpose\n",
    "task1_data = task1_data.transpose(1, 2)\n",
    "task2_data = task2_data.transpose(1, 2)\n",
    "task3_data = task3_data.transpose(1, 2)\n",
    "task4_data = task4_data.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c7d65f-18e0-4fec-aa28-2bee8b526ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for task 1~4\n",
    "dataset1 = torch.utils.data.TensorDataset(task1_data, task1_labels)\n",
    "dataset2 = torch.utils.data.TensorDataset(task2_data, task2_labels)\n",
    "dataset3 = torch.utils.data.TensorDataset(task3_data, task3_labels)\n",
    "dataset4 = torch.utils.data.TensorDataset(task4_data, task4_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e28c1ad-0515-4a98-aaa6-2392e543678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_size = int(0.8 * len(dataset1))\n",
    "test_size = len(dataset1) - train_size\n",
    "\n",
    "train_dataset1, test_dataset1 = random_split(dataset1, [train_size, test_size])\n",
    "train_dataset2, test_dataset2 = random_split(dataset2, [train_size, test_size])\n",
    "train_dataset3, test_dataset3 = random_split(dataset3, [train_size, test_size])\n",
    "train_dataset4, test_dataset4 = random_split(dataset4, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2457011f-e671-428d-8834-ce4a5a91610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_datasets.append((train_dataset1, test_dataset1))\n",
    "task_datasets.append((train_dataset2, test_dataset2))\n",
    "task_datasets.append((train_dataset3, test_dataset3))\n",
    "task_datasets.append((train_dataset4, test_dataset4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a653b33f-b08d-40a8-b7da-b47279c25873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义WDCNN模型\n",
    "class WDCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(WDCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 256, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ac1b37-e9d6-4428-b99b-36fbbdeabedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device, dtype=torch.double)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "# 定义测试函数\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device, dtype=torch.double)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "# 初始化参数\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "289f56b3-7045-4a78-8297-03cef726a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建和加载第一个任务的训练和测试数据集\n",
    "# task1_train_dataset = ...\n",
    "# task1_test_dataset = ...\n",
    "task1_train_dataloader = torch.utils.data.DataLoader(train_dataset1, batch_size=batch_size, shuffle=True)\n",
    "task1_test_dataloader = torch.utils.data.DataLoader(test_dataset1, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 创建WDCNN模型\n",
    "model = WDCNN(num_classes).to(device)\n",
    "model.double()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34099ba4-cb32-45c7-b2c8-6442052f5a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: Train Loss: 0.4883, Test Loss: 0.0893, Test Accuracy: 0.9707\n",
      "Epoch 2/5: Train Loss: 0.0563, Test Loss: 0.0297, Test Accuracy: 0.9921\n",
      "Epoch 3/5: Train Loss: 0.0454, Test Loss: 0.0258, Test Accuracy: 0.9904\n",
      "Epoch 4/5: Train Loss: 0.0104, Test Loss: 0.0363, Test Accuracy: 0.9875\n",
      "Epoch 5/5: Train Loss: 0.0055, Test Loss: 0.0714, Test Accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "# 训练第一个任务\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练\n",
    "    train_loss = train(model, task1_train_dataloader, criterion, optimizer, device)\n",
    "    # 测试\n",
    "    test_loss, test_accuracy = test(model, task1_test_dataloader, criterion, device)\n",
    "    # 打印训练和测试结果\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302d08fb-7d3b-47d5-9f47-b00ccc5be5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5/5: Train Loss: 0.0055, Test Loss: 4.6439, Test Accuracy: 0.5918\n",
      "Task 2 - Epoch 5/5: Train Loss: 0.0055, Test Loss: 6.0222, Test Accuracy: 0.5725\n",
      "Task 3 - Epoch 5/5: Train Loss: 0.0055, Test Loss: 4.4044, Test Accuracy: 0.5950\n"
     ]
    }
   ],
   "source": [
    "# 其余任务测试\n",
    "for task in range(1, 4):\n",
    "    task_test_dataloader = torch.utils.data.DataLoader(task_datasets[task][1], batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    test_loss, test_accuracy = test(model, task_test_dataloader, criterion, device)\n",
    "    # 打印训练和测试结果\n",
    "    print(f\"Task {task} - Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3b5d3e0-55d4-4721-8077-7146794590c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结卷积层参数\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.conv2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "407ba6ef-3c31-45ec-9a66-ba1000b3d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建新的分类器并保存与任务相关的模型\n",
    "# task1_classifier = nn.Sequential(\n",
    "#     nn.Linear(64 * 256, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(128, num_classes)\n",
    "# )\n",
    "# # task1_classifier.load_state_dict(model.fc.state_dict())\n",
    "# torch.save(task1_classifier.state_dict(), \"./parameters/task1_classifier.pt\")\n",
    "\n",
    "# 创建新的分类器并保存与任务相关的模型\n",
    "task1_classifier = nn.Linear(128, num_classes).to(device)\n",
    "task1_classifier.load_state_dict(model.fc2.state_dict())\n",
    "torch.save(task1_classifier.state_dict(), \"./parameters/task1_classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb27685b-be9e-4951-a622-3108255b334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5abd90b2-a9a2-4e8a-a2a3-6873d4dc0f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 1/5: Train Loss: 1.1132, Test Loss: 0.4157, Test Accuracy: 0.8714\n",
      "Task 2 - Epoch 2/5: Train Loss: 0.2882, Test Loss: 0.2696, Test Accuracy: 0.9068\n",
      "Task 2 - Epoch 3/5: Train Loss: 0.1432, Test Loss: 0.2321, Test Accuracy: 0.9268\n",
      "Task 2 - Epoch 4/5: Train Loss: 0.1358, Test Loss: 0.2123, Test Accuracy: 0.9432\n",
      "Task 2 - Epoch 5/5: Train Loss: 0.0955, Test Loss: 0.1875, Test Accuracy: 0.9493\n",
      "Task 3 - Epoch 1/5: Train Loss: 0.0819, Test Loss: 0.1408, Test Accuracy: 0.9307\n",
      "Task 3 - Epoch 2/5: Train Loss: 0.0673, Test Loss: 0.0694, Test Accuracy: 0.9879\n",
      "Task 3 - Epoch 3/5: Train Loss: 0.0402, Test Loss: 0.0470, Test Accuracy: 0.9875\n",
      "Task 3 - Epoch 4/5: Train Loss: 0.0232, Test Loss: 0.0529, Test Accuracy: 0.9843\n",
      "Task 3 - Epoch 5/5: Train Loss: 0.0191, Test Loss: 0.0608, Test Accuracy: 0.9775\n",
      "Task 4 - Epoch 1/5: Train Loss: 1.0906, Test Loss: 0.9382, Test Accuracy: 0.8429\n",
      "Task 4 - Epoch 2/5: Train Loss: 0.5822, Test Loss: 0.8664, Test Accuracy: 0.7639\n",
      "Task 4 - Epoch 3/5: Train Loss: 0.3327, Test Loss: 0.7581, Test Accuracy: 0.7664\n",
      "Task 4 - Epoch 4/5: Train Loss: 0.2101, Test Loss: 0.7029, Test Accuracy: 0.7771\n",
      "Task 4 - Epoch 5/5: Train Loss: 0.1519, Test Loss: 0.6992, Test Accuracy: 0.7729\n"
     ]
    }
   ],
   "source": [
    "# 加载并适应其余任务\n",
    "for task in range(1, 4):\n",
    "    # 构建和加载第task任务的训练和测试数据集\n",
    "    # task_train_dataset = ...\n",
    "    # task_test_dataset = ...\n",
    "    # print(f'train_dataset{task}')\n",
    "    sampled_train_dataset = random.sample(list(task_datasets[task][0]), 50)\n",
    "    # print(task_datasets[task][0][:50])\n",
    "    task_train_dataloader = torch.utils.data.DataLoader(sampled_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    task_test_dataloader = torch.utils.data.DataLoader(task_datasets[task][1], batch_size=batch_size, shuffle=False)\n",
    "    # print(task_train_dataloader)\n",
    "    \n",
    "    # 加载任务相关的分类器\n",
    "    classifier = nn.Linear(128, num_classes).to(device)\n",
    "    classifier.load_state_dict(torch.load(f\"./parameters/task1_classifier.pt\"))\n",
    "\n",
    "    # 替换模型的分类器\n",
    "    model.fc2 = classifier\n",
    "    model.double()\n",
    "\n",
    "    # 重新定义优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 训练\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练\n",
    "        train_loss = train(model, task_train_dataloader, criterion, optimizer, device)\n",
    "        # 测试\n",
    "        test_loss, test_accuracy = test(model, task_test_dataloader, criterion, device)\n",
    "        # 打印训练和测试结果\n",
    "        print(f\"Task {task+1} - Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # 保存与任务相关的模型\n",
    "    # torch.save(model.state_dict(), f\"task{task}_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a34b3-5c59-4e72-b15d-9bb2ef61da67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_v1.9_gpu",
   "language": "python",
   "name": "torch_v1.9_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
