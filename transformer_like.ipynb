{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61cb95e-eb10-4261-85f9-5cfb3ee25411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BearingFaultModel(\n",
      "  (embedding): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src2 = self.self_attn(src, src, src, attn_mask=src_mask)[0]\n",
    "        src = src + self.dropout(src2)\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
    "        src = src + self.dropout(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, num_layers, dropout):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "    \n",
    "    def forward(self, src, src_mask=None):\n",
    "        src = self.encoder(src, src_mask=src_mask)\n",
    "        return src\n",
    "\n",
    "class BearingFaultModel(nn.Module):\n",
    "    # def __init__(self, input_dim, hidden_dim, output_dim, num_layers, nhead, dim_feedforward, dropout):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, nhead, dim_feedforward, dropout):\n",
    "        super(BearingFaultModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        # self.transformer_encoder = TransformerEncoder(hidden_dim, nhead, dim_feedforward, num_layers, dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, nhead, dim_feedforward, dropout)\n",
    "        # self.transformer_encoder = TransformerEncoder(hidden_dim, nhead, dim_feedforward, num_layers, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        src = self.transformer_encoder(src)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        src = torch.mean(src, dim=1)  # 平均池化\n",
    "        src = self.fc(src)\n",
    "        return src\n",
    "\n",
    "# 定义模型参数\n",
    "input_dim = 1024\n",
    "hidden_dim = 256\n",
    "output_dim = 10\n",
    "num_layers = 2\n",
    "nhead = 4\n",
    "dim_feedforward = 512\n",
    "dropout = 0.1\n",
    "\n",
    "# 创建模型实例\n",
    "model = BearingFaultModel(input_dim, hidden_dim, output_dim, num_layers, nhead, dim_feedforward, dropout)\n",
    "\n",
    "# 输出模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ddd5dec-ea29-4db7-9849-cd9934dd4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e5314a9-b2d6-4267-9cab-d8f36dbb6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "task1_data = np.load('./cwru1_X_train.npy')\n",
    "task1_labels = np.load('./cwru2_y_train.npy')\n",
    "\n",
    "# Task 2\n",
    "task2_data = np.load('./cwru2_X_train.npy')\n",
    "task2_labels = np.load('./cwru2_y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a50671f-b58d-4dec-84c6-3c4030ad14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "task1_data = torch.from_numpy(task1_data)\n",
    "task1_labels = torch.from_numpy(task1_labels)\n",
    "\n",
    "# Task 2\n",
    "task2_data = torch.from_numpy(task2_data)\n",
    "task2_labels = torch.from_numpy(task2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c8ad04-b8ec-4c97-9d74-cfdf2e6af0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cfc0ebf-30af-4433-b9a9-1d93c63fb878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transpose\n",
    "task1_data = task1_data.transpose(1, 2)\n",
    "task2_data = task2_data.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd47972c-5b27-4fa5-b668-5d3aa07a2d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.30257142857142855\n",
      "Epoch 2 - Accuracy: 0.32821428571428574\n",
      "Epoch 3 - Accuracy: 0.35414285714285715\n",
      "Epoch 4 - Accuracy: 0.3637142857142857\n",
      "Epoch 5 - Accuracy: 0.3226428571428571\n",
      "Epoch 6 - Accuracy: 0.3455\n",
      "Epoch 7 - Accuracy: 0.3999285714285714\n",
      "Epoch 8 - Accuracy: 0.3425714285714286\n",
      "Epoch 9 - Accuracy: 0.3777142857142857\n",
      "Epoch 10 - Accuracy: 0.3653571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 数据准备\n",
    "# 假设您已经将数据准备成训练集和测试集的形式，分别为train_data, train_labels, test_data, test_labels\n",
    "\n",
    "# 转换为Tensor格式\n",
    "# train_data = torch.Tensor(task1_data)\n",
    "# train_labels = torch.LongTensor(task1_labels)\n",
    "# test_data = torch.Tensor(task2_data)\n",
    "# test_labels = torch.LongTensor(task2_labels)\n",
    "train_data = task1_data\n",
    "train_labels = task1_labels\n",
    "test_data = task2_data\n",
    "test_labels = task2_labels\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 创建模型实例\n",
    "# model = BearingFaultModel(input_dim, hidden_dim, output_dim, num_layers, nhead, dim_feedforward, dropout)\n",
    "model = BearingFaultModel(input_dim, hidden_dim, output_dim, num_layers, nhead, dim_feedforward, dropout).to(device)\n",
    "model.double()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 模型训练\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i in range(0, len(train_data), batch_size):\n",
    "        batch_data = train_data[i:i+batch_size].to(device, dtype=torch.double)\n",
    "        batch_labels = train_labels[i:i+batch_size].to(device, dtype=torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 模型评估\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_data)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(test_labels, predicted)\n",
    "        print(f\"Epoch {epoch+1} - Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fd6f1-bc74-433c-9f9d-cdde4bca861a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_v1.9_gpu",
   "language": "python",
   "name": "torch_v1.9_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
